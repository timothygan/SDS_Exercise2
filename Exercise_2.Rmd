---
title: "Exercise_2"
output: github_document
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mosaic)
library(FNN)
sclass = read.csv("data/sclass.csv")

rmse = function(y, ypred) {
  sqrt(mean(data.matrix((y-ypred)^2)))
}
k_vs_rmean = NULL
k_vs_rmean_saratoga = NULL
rmse_vals = NULL
set.seed(3)
```

## GitHub Documents

This is an R Markdown format used for publishing markdown documents to GitHub. When you click the **Knit** button all R code chunks are run and a markdown file (.md) suitable for publishing to GitHub is generated.

## KNN Practice

We wil be using the K-nearest neighbors technique to predict the price of Mercedes S Class vehicles based on gas mileage. We will be distinguishing these S Class vehicles by trim. In particular, we will be focusing on just two values of trim: 350 and 65 AMG, and finding optimal values of K for predicting the price of each.

### KNN functions for 350 trim vehciles
```{r sclass_350, echo=FALSE, autodep=TRUE}
# Focus on 2 trim levels: 350 and 65 AMG
sclass350 = subset(sclass, trim == '350')
dim(sclass350)

N = nrow(sclass350)
N_train = floor(0.8*N)
N_test = N - N_train
train_ind = sample.int(N, N_train, replace=FALSE)

train = sclass350[train_ind,]
test = sclass350[-train_ind,]
test = arrange(test, mileage)

X_train = select(train, mileage)
y_train = select(train, price)
X_test = select(test, mileage)
y_test = select(test, price)


# KNN 250


knn250 = knn.reg(train = X_train, test = X_test, y = y_train, k=250)
ypred_knn250 = knn250$pred

knn3 = knn.reg(train = X_train, test = X_test, y = y_train, k=3)
ypred_knn3 = knn3$pred

knn5 = knn.reg(train = X_train, test = X_test, y = y_train, k=5)
ypred_knn5 = knn5$pred
knn10 = knn.reg(train = X_train, test = X_test, y = y_train, k=10)
ypred_knn10 = knn10$pred
knn20 = knn.reg(train = X_train, test = X_test, y = y_train, k=20)
ypred_knn20 = knn20$pred
knn50 = knn.reg(train = X_train, test = X_test, y = y_train, k=50)
ypred_knn50 = knn50$pred
knn100 = knn.reg(train = X_train, test = X_test, y = y_train, k=100)
ypred_knn100 = knn100$pred

test$ypred_knn250 = ypred_knn250

test$ypred_knn3 = ypred_knn3
test$ypred_knn5 = ypred_knn5
test$ypred_knn10 = ypred_knn10
test$ypred_knn20 = ypred_knn20
test$ypred_knn50 = ypred_knn50
test$ypred_knn100 = ypred_knn100

p_test_3 = ggplot(data = test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  theme_bw(base_size=18) + geom_path(aes(x = mileage, y = ypred_knn3), color='red')

p_test_3
rmse(y_test, ypred_knn3)


p_test_10 = ggplot(data = test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  theme_bw(base_size=18) + geom_path(aes(x = mileage, y = ypred_knn10), color='red')

p_test_10
rmse(y_test, ypred_knn10)

p_test_50 = ggplot(data = test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  theme_bw(base_size=18) + geom_path(aes(x = mileage, y = ypred_knn50), color='red')

p_test_50
rmse(y_test, ypred_knn50)

kframe <- data.frame("K" = c(), "RMEAN" =c())
i <- 3
while (i <= 250) {
  d = data.frame("K" = i, "RMEAN" = rmse(y_test, knn.reg(train = X_train, test = X_test, y = y_train, k=i)$pred))
  
  kframe = rbind(kframe, d)
  i = i + 1

}

k_vs_rmean = ggplot(data = kframe) + 
  geom_point(mapping = aes(x = K, y = RMEAN), color='lightgrey') + 
  theme_bw(base_size=18) + geom_path(aes(x = K, y = RMEAN), color='red')
```

Here we plot the average RMSE for each value of K from 3 to 250, and find that the optimal value of K is `r which(kframe$RMEAN==min(kframe$RMEAN)) + 2` 

```{r sclass_350_2, echo=FALSE, autodep=TRUE}

k_vs_rmean

```

### 65 AMG


```{r sclass_65, echo=FALSE}
# Focus on 2 trim levels: 350 and 65 AMG
sclass65 = subset(sclass, trim == '65 AMG')
dim(sclass65)

N = nrow(sclass65)
N_train = floor(0.8*N)
N_test = N - N_train
train_ind = sample.int(N, N_train, replace=FALSE)

train = sclass65[train_ind,]
test = sclass65[-train_ind,]
test = arrange(test, mileage)
train = arrange(train, mileage)

X_train = select(train, mileage)
y_train = select(train, price)
X_test = select(test, mileage)
y_test = select(test, price)

knn200 = knn.reg(train = X_train, test = X_test, y = y_train, k=200)
ypred_knn200 = knn200$pred

knn3 = knn.reg(train = X_train, test = X_test, y = y_train, k=3)
ypred_knn3 = knn3$pred

knn5 = knn.reg(train = X_train, test = X_test, y = y_train, k=5)
ypred_knn5 = knn5$pred
knn10 = knn.reg(train = X_train, test = X_test, y = y_train, k=10)
ypred_knn10 = knn10$pred
knn20 = knn.reg(train = X_train, test = X_test, y = y_train, k=20)
ypred_knn20 = knn20$pred
knn50 = knn.reg(train = X_train, test = X_test, y = y_train, k=50)
ypred_knn50 = knn50$pred
knn100 = knn.reg(train = X_train, test = X_test, y = y_train, k=100)
ypred_knn100 = knn100$pred

test$ypred_knn200 = ypred_knn200

test$ypred_knn3 = ypred_knn3
test$ypred_knn5 = ypred_knn5
test$ypred_knn10 = ypred_knn10
test$ypred_knn20 = ypred_knn20
test$ypred_knn50 = ypred_knn50
test$ypred_knn100 = ypred_knn100

p_test_3 = ggplot(data = test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  theme_bw(base_size=18) + geom_path(aes(x = mileage, y = ypred_knn3), color='red')

p_test_3
rmse(y_test, ypred_knn3)

p_test_10 = ggplot(data = test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  theme_bw(base_size=18) + geom_path(aes(x = mileage, y = ypred_knn10), color='red')

p_test_10
rmse(y_test, ypred_knn10)


p_test_50 = ggplot(data = test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  theme_bw(base_size=18) + geom_path(aes(x = mileage, y = ypred_knn50), color='red')

p_test_50
rmse(y_test, ypred_knn50)

kframe <- data.frame("K" = c(), "RMEAN" =c())
i <- 3
while (i <= 200) {
  d = data.frame("K" = i, "RMEAN" = rmse(y_test, knn.reg(train = X_train, test = X_test, y = y_train, k=i)$pred))
  kframe = rbind(kframe, d)
  i = i + 1
}
k_vs_rmean = ggplot(data = kframe) + 
  geom_point(mapping = aes(x = K, y = RMEAN), color='lightgrey') + 
  theme_bw(base_size=18) + geom_path(aes(x = K, y = RMEAN), color='red')
```

Here we plot the average RMSE for each value of K from 3 to 200, and find that the optimal value of K is `r which(kframe$RMEAN==min(kframe$RMEAN)) + 2`

```{r sclass_65_2, echo=FALSE, autodep=TRUE}

k_vs_rmean

```

### Conclusion

The optimal value of K is larger for the 350 trim vehicles than the 65 AMG. One explanation for this is that the sample set of 350 trim vehichles is also larger than the set of 65 AMG vehicles. As the value of K gets closer to the size of the entire sample, KNN becomes less useful in estimating the price for a specific mileage value.  



``` {r saratoga, echo=FALSE, autodep=TRUE, warning=FALSE}
n = nrow(SaratogaHouses)
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train





rmse_vals = do(100)*{
  
  # re-split into train and test cases with the same sample sizes
  train_cases = sample.int(n, n_train, replace=FALSE)
  test_cases = setdiff(1:n, train_cases)
  saratoga_train = SaratogaHouses[train_cases,]
  saratoga_test = SaratogaHouses[test_cases,]
  
  # Fit to the training data
  lm1 = lm(price ~ lotSize + bedrooms + bathrooms, data=saratoga_train)
  lm2 = lm(price ~ . - sewer - waterfront - landValue - newConstruction, data=saratoga_train)
  lm3 = lm(price ~ (. - sewer - waterfront - landValue - newConstruction)^2, data=saratoga_train)
  
  lm_dominate = lm(price ~ lotSize + age + livingArea + pctCollege + 
                     bedrooms + fireplaces + bathrooms + rooms + heating + fuel +
                     centralAir + lotSize:heating + livingArea:rooms + newConstruction + livingArea:newConstruction, data=saratoga_train)
  
  

  
  our_model = lm(price ~ . - fireplaces - sewer - heating, data=saratoga_train)
  
  
  #KNN
  Xtrain = model.matrix(~ . - (price + sewer + fireplaces + heating) - 1, data=saratoga_train)
  Xtest = model.matrix(~ . - (price + sewer + fireplaces + heating) - 1, data=saratoga_test)

  ytrain = saratoga_train$price
  ytest = saratoga_test$price

  scale_train = apply(Xtrain, 2, sd)
  Xtilde_train = scale(Xtrain, scale = scale_train)
  Xtilde_test = scale(Xtest, scale = scale_train)

  head(Xtrain, 2)
  head(Xtilde_train, 2) %>% round(3)
  knn_model = knn.reg(Xtilde_train, Xtilde_test, ytrain, k=7)
  
  # Predictions out of sample
  yhat_test1 = predict(lm1, saratoga_test)
  yhat_test2 = predict(lm2, saratoga_test)
  yhat_test3 = predict(lm3, saratoga_test)
  yhat_test4 = predict(lm_dominate, saratoga_test)
  yhat_test5 = predict(our_model, saratoga_test)

  
  c(rmse(saratoga_test$price, yhat_test1),
    rmse(saratoga_test$price, yhat_test2),
    #rmse(saratoga_test$price, yhat_test3),
    rmse(saratoga_test$price, yhat_test4),
    rmse(saratoga_test$price, yhat_test5),
    rmse(ytest, knn_model$pred))
}

kframe <- data.frame("K" = c(), "RMEAN_AVERAGE" =c())
i <- 3
while(i <= 100){
  avg_cols = do(100)*{
    
    # re-split into train and test cases with the same sample sizes
    train_cases = sample.int(n, n_train, replace=FALSE)
    test_cases = setdiff(1:n, train_cases)
    saratoga_train = SaratogaHouses[train_cases,]
    saratoga_test = SaratogaHouses[test_cases,]
    Xtrain = model.matrix(~ . - (price + sewer + fireplaces + heating) - 1, data=saratoga_train)
    Xtest = model.matrix(~ . - (price + sewer + fireplaces + heating) - 1, data=saratoga_test)
    
    ytrain = saratoga_train$price
    ytest = saratoga_test$price
    
    scale_train = apply(Xtrain, 2, sd)
    Xtilde_train = scale(Xtrain, scale = scale_train)
    Xtilde_test = scale(Xtest, scale = scale_train)
    
    head(Xtrain, 2)
    head(Xtilde_train, 2) %>% round(3)
    knn_model = knn.reg(Xtilde_train, Xtilde_test, ytrain, k=i)
    
    c(rmse(ytest, knn_model$pred))
  }
  d = data.frame("K" = i, "RMEAN_AVERAGE" = mean(avg_cols[["result"]]))
  
  kframe = rbind(kframe, d)
  i = i + 1
  
}


k_vs_rmean_saratoga = ggplot(data = kframe) + 
  geom_point(mapping = aes(x = K, y = RMEAN_AVERAGE), color='lightgrey') + 
  theme_bw(base_size=18) + geom_path(aes(x = K, y = RMEAN_AVERAGE), color='red')

k_vs_rmean_saratoga

rmse_vals
colMeans(rmse_vals)
boxplot(rmse_vals)


```